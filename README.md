# Docker и контейнеризация как современная альтернатива традиционной виртуализации

Реферат по дисциплине «Администрирование информационных систем».

## Содержание
- [Введение](#sec-intro)
- [1 Теоретическая часть](#sec-1)
  - [1.1 Традиционная виртуализация: назначение и основные подходы](#sec-1-1)
  - [1.2 Контейнеризация: виртуализация на уровне операционной системы](#sec-1-2)
  - [1.3 Docker: архитектура и ключевые понятия](#sec-1-3)
  - [1.4 Сравнение контейнеров Docker и виртуальных машин](#sec-1-4)
  - [1.5 Ограничения и вопросы безопасности контейнеров](#sec-1-5)
- [2 Практическая часть](#sec-2)
  - [2.1 Подготовка среды и установка Docker](#sec-2-1)
  - [2.2 Создание Dockerfile для веб‑приложения](#sec-2-2)
  - [2.3 Оркестрация нескольких сервисов с Docker Compose](#sec-2-3)
  - [2.4 Сравнение с развертыванием на виртуальной машине](#sec-2-4)
- [Заключение](#sec-conclusion)
- [Список литературы](#sec-references)

<a id="sec-intro"></a>
## Введение

Виртуализация стала одной из базовых технологий современной ИТ‑инфраструктуры: она позволяет запускать несколько изолированных сред на одном физическом сервере, повышая загрузку ресурсов и упрощая управление. Долгое время основным способом такой изоляции были виртуальные машины (VM), каждая из которых содержит собственную гостевую операционную систему и набор системных библиотек <sup><a href="#ref-5">[5]</a></sup>.

Параллельно с развитием виртуализации изменились требования к развертыванию приложений. Для веб‑сервисов и микросервисной архитектуры важны скорость выпуска релизов, повторяемость окружений и возможность масштабирования «по требованию». Эти задачи привели к широкому распространению контейнеризации — подхода, при котором изоляция достигается на уровне ядра операционной системы, а приложение поставляется вместе со своими зависимостями в виде образа контейнера <sup><a href="#ref-8">[8]</a></sup>.

Наиболее известной и массовой реализацией контейнерного подхода стала платформа Docker. Она стандартизировала работу с образами и контейнерами, упростила сборку и доставку приложений, а также сформировала экосистему инструментов (Dockerfile, registry, Compose и др.) <sup><a href="#ref-1">[1]</a></sup>.

Цель работы — рассмотреть Docker и контейнеризацию как современную альтернативу традиционной виртуализации, выделить ключевые отличия этих подходов и показать пример практического применения контейнеров. Для достижения цели решаются следующие задачи: 1) описать принципы виртуальных машин и гипервизоров; 2) раскрыть механизм контейнерной изоляции в Linux; 3) описать архитектуру Docker и основные сущности; 4) сравнить контейнеры и виртуальные машины по основным критериям; 5) привести пример развертывания простого приложения с помощью Docker и Docker Compose.

<a id="sec-1"></a>
## 1 Теоретическая часть

<a id="sec-1-1"></a>
### 1.1 Традиционная виртуализация: назначение и основные подходы

Традиционная виртуализация основана на создании виртуальной машины — программной модели компьютера, которая получает часть ресурсов физического хоста (процессорное время, оперативную память, дисковое пространство, сетевые интерфейсы) и запускает собственную гостевую операционную систему. Управление аппаратными ресурсами осуществляет гипервизор — слой, распределяющий ресурсы между VM и обеспечивающий изоляцию <sup><a href="#ref-5">[5]</a></sup>.

По архитектуре выделяют два основных типа гипервизоров. Гипервизор типа 1 (bare‑metal) устанавливается непосредственно на «железо» и предоставляет высокую производительность и управляемость; к этой категории относят, например, VMware ESXi и Microsoft Hyper‑V Server <sup><a href="#ref-5">[5]</a></sup>. Гипервизор типа 2 (hosted) работает как приложение внутри основной ОС, что упрощает установку и подходит для учебных и тестовых сценариев (пример — Oracle VirtualBox) <sup><a href="#ref-6">[6]</a></sup>.

Для Linux широко используется KVM (Kernel‑based Virtual Machine), который реализует аппаратную виртуализацию на базе модулей ядра и обычно работает совместно с QEMU. В такой связке KVM отвечает за ускорение виртуализации за счет аппаратных расширений (Intel VT‑x, AMD‑V), а QEMU эмулирует устройства и обеспечивает запуск гостевой ОС <sup><a href="#ref-7">[7]</a></sup>.

Преимущества VM заключаются в сильной изоляции (каждая VM — отдельная ОС), высокой совместимости (можно запускать разные ОС на одном хосте) и зрелых механизмах администрирования. Однако у виртуальных машин есть и издержки: гостевая ОС занимает значительный объём диска и памяти, старт VM обычно занимает больше времени, а плотность размещения (количество изолированных сред на одном сервере) как правило ниже по сравнению с контейнерами. Эти особенности становятся критичными в задачах, где нужно быстро масштабировать однотипные сервисы и часто пересобирать окружения.

<a id="sec-1-2"></a>
### 1.2 Контейнеризация: виртуализация на уровне операционной системы

Контейнеризация отличается от VM тем, что не запускает отдельную гостевую операционную систему. Вместо этого несколько изолированных процессов работают в пределах одного ядра ОС хоста. У каждого контейнера есть собственное «пространство» процессов, сетевых интерфейсов, точек монтирования и других ресурсов, но ядро при этом общее для всех контейнеров <sup><a href="#ref-3">[3]</a></sup>.

В Linux изоляция контейнеров опирается на два ключевых механизма: namespaces и cgroups. Namespaces ограничивают видимость ресурсов (например, PID namespace скрывает процессы других контейнеров; network namespace изолирует сетевой стек; mount namespace — точки монтирования). Control groups (cgroups) задают ограничения и учет ресурсов: сколько CPU и памяти может потребить контейнер, какие устройства ему доступны и т.п. <sup><a href="#ref-3">[3]</a></sup>, <sup><a href="#ref-4">[4]</a></sup>.

Контейнеры также используют файловые системы с поддержкой слоев (copy‑on‑write), благодаря чему образ можно собирать из повторно используемых слоев. Это сокращает размер хранимых артефактов и ускоряет развертывание, особенно когда множество сервисов используют общую базу зависимостей <sup><a href="#ref-1">[1]</a></sup>.

Со временем вокруг контейнеров сформировались стандарты, обеспечивающие переносимость между инструментами. Open Container Initiative (OCI) определяет спецификации формата образа и интерфейсы исполнения контейнеров. Благодаря этому, хотя Docker популяризировал подход, контейнерная экосистема не замыкается на одной реализации и поддерживает разные runtime‑решения <sup><a href="#ref-2">[2]</a></sup>.

<a id="sec-1-3"></a>
### 1.3 Docker: архитектура и ключевые понятия

Docker — платформа, которая делает работу с контейнерами удобной на практике. В типичной архитектуре Docker Engine выделяют клиент (docker CLI) и демон (dockerd), который выполняет операции сборки, запуска и управления контейнерами. Внутри Docker Engine используются компоненты containerd и runtime (например, runc), отвечающие за непосредственное создание контейнеров на основе возможностей ядра и спецификаций OCI <sup><a href="#ref-1">[1]</a></sup>, <sup><a href="#ref-2">[2]</a></sup>.

Базовые сущности Docker следующие:

- образ (image) — неизменяемый шаблон, включающий файловую систему приложения и его зависимости; образ состоит из слоев и обычно хранится в registry;
- контейнер (container) — запущенный экземпляр образа, то есть процесс (или группа процессов) в изолированном окружении;
- Dockerfile — сценарий сборки образа, описывающий шаги (базовый образ, копирование файлов, установка зависимостей, команду запуска);
- registry — репозиторий образов (публичный или частный), откуда образы можно скачивать и куда их можно публиковать;
- volume — механизм хранения данных вне жизненного цикла контейнера (для БД, логов, кэшей и т.п.);
- network — виртуальная сеть Docker, позволяющая контейнерам взаимодействовать по DNS‑именам и изолировать трафик между группами сервисов.

Сборка образов в Docker строится вокруг принципа повторяемости: один и тот же Dockerfile при одинаковом контексте дает одинаковый результат. На практике это помогает фиксировать зависимости приложения и уменьшать различия между окружениями разработки, тестирования и эксплуатации. При изменении отдельных шагов пересобираются только соответствующие слои, что ускоряет итерации <sup><a href="#ref-1">[1]</a></sup>.

Docker поддерживает различные режимы сетевого взаимодействия (bridge, host, overlay и др.), а также изоляцию ресурсов через ограничения CPU/памяти и квоты на ввод‑вывод. При работе с stateful‑компонентами (например, базами данных) обычно используют тома (volumes) или внешние хранилища, чтобы данные сохранялись при обновлении контейнера <sup><a href="#ref-1">[1]</a></sup>.

Для запуска нескольких взаимосвязанных контейнеров в одной конфигурации применяется Docker Compose. Он позволяет описать набор сервисов (например, приложение, база данных, прокси), их сети, переменные окружения и тома в одном YAML‑файле и запускать всё одной командой. Такой подход особенно удобен для учебных работ, локальной разработки и небольших серверных развертываний <sup><a href="#ref-1">[1]</a></sup>.

<a id="sec-1-4"></a>
### 1.4 Сравнение контейнеров Docker и виртуальных машин

Контейнеры и виртуальные машины решают схожую задачу — изолировать приложения и их окружение, — но делают это разными способами. В VM изоляция достигается за счет отдельной гостевой ОС и виртуализированного «железа», что дает высокий уровень разделения, но увеличивает накладные расходы. В контейнерах изоляция обеспечивается на уровне ядра (namespaces/cgroups), поэтому они легче и быстрее, но сильнее зависят от ОС хоста <sup><a href="#ref-3">[3]</a></sup>, <sup><a href="#ref-4">[4]</a></sup>, <sup><a href="#ref-5">[5]</a></sup>.

Сравнение ключевых характеристик приведено в таблице 1.1.

**Таблица 1.1 — Сравнение виртуальных машин и контейнеров**

| Критерий | Виртуальные машины | Контейнеры (Docker) |
| --- | --- | --- |
| Уровень изоляции | Высокая: отдельная гостевая ОС и виртуальное оборудование | Высокая, но общее ядро ОС; изоляция процессов через namespaces/cgroups |
| Потребление ресурсов | Выше (ОС в каждой VM, больше RAM/диска) | Ниже (нет гостевой ОС, образы переиспользуют слои) |
| Скорость запуска | Обычно минуты или десятки секунд | Обычно секунды и меньше |
| Переносимость | Переносимы образы VM, но зависят от гипервизора/формата | Переносимы образы OCI; запуск на совместимых runtime |
| Совместимость ОС | Можно запускать разные ОС (Windows, Linux и т.д.) | Зависимость от ядра хоста (Linux‑контейнеры требуют Linux‑ядро) |
| Типовые сценарии | Монолитные приложения, изоляция арендаторов, разнородные ОС | Микросервисы, CI/CD, однотипные сервисы, быстрая доставка |

Из таблицы видно, что контейнеры выигрывают по скорости запуска и плотности размещения, что делает их удобными для микросервисных систем и задач масштабирования. Виртуальные машины, в свою очередь, обеспечивают более строгую границу изоляции между окружениями и позволяют запускать разные ОС на одном хосте, поэтому они по‑прежнему востребованы в корпоративных инфраструктурах, где требуется разграничение арендаторов и поддержка разнородных платформ <sup><a href="#ref-5">[5]</a></sup>.

На практике подходы часто комбинируют: контейнеры запускают внутри виртуальных машин. Это позволяет получить управляемость и изоляцию VM на уровне инфраструктуры и гибкость контейнеров на уровне приложений. Подобная схема распространена в облаках и на платформах оркестрации, где узлы кластера представлены виртуальными машинами, а рабочие нагрузки исполняются в контейнерах <sup><a href="#ref-9">[9]</a></sup>.

<a id="sec-1-5"></a>
### 1.5 Ограничения и вопросы безопасности контейнеров

Несмотря на очевидные преимущества, контейнеризация не является «полной заменой» виртуализации во всех сценариях. Ключевое ограничение — общее ядро ОС. Если требуются разные семейства ОС, специфические драйверы или строгие требования к изоляции, VM остаются более универсальным вариантом <sup><a href="#ref-5">[5]</a></sup>.

Безопасность контейнеров включает несколько уровней: безопасность образов (отсутствие уязвимых пакетов), безопасность исполнения (минимальные привилегии, ограничения возможностей ядра), безопасность среды (изоляция сети, контроль доступа к registry). Рекомендации по контейнерной безопасности и типовым угрозам описаны, например, в руководстве NIST SP 800‑190 <sup><a href="#ref-10">[10]</a></sup>.

На практике для снижения рисков применяют следующие меры: запуск процессов не от root‑пользователя, использование rootless‑режимов там, где это возможно; минимизация образов (alpine/distroless), регулярное обновление базовых образов; сканирование образов на уязвимости; запрет привилегированных контейнеров и ограничение Linux capabilities; отделение секретов (пароли, токены) от Dockerfile и хранение их в специализированных хранилищах <sup><a href="#ref-1">[1]</a></sup>, <sup><a href="#ref-10">[10]</a></sup>.

Также важно учитывать хранение данных. Контейнеры по своей природе «одноразовые»: контейнер можно безопасно пересоздавать, но данные должны жить отдельно (volumes, внешние БД и хранилища). В противном случае обновление версии приложения может привести к потере состояния <sup><a href="#ref-1">[1]</a></sup>.

<a id="sec-2"></a>
## 2 Практическая часть

<a id="sec-2-1"></a>
### 2.1 Подготовка среды и установка Docker

В практической части рассматривается пример контейнеризации небольшого веб‑приложения и его запуска в Docker. В качестве целевой платформы используется Linux‑сервер (или виртуальная машина) с доступом в интернет. В реальной инфраструктуре способ установки зависит от дистрибутива, однако общая логика одинакова: устанавливаются пакеты Docker Engine и утилиты командной строки <sup><a href="#ref-1">[1]</a></sup>.

Ниже приведен пример команд для Debian/Ubuntu‑подобных систем (команды выполняются от имени администратора):

```bash
sudo apt-get update
sudo apt-get install -y ca-certificates curl gnupg
# добавление репозитория Docker (пример)
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo $VERSION_CODENAME) stable" | sudo tee /etc/apt/sources.list.d/docker.list

sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

После установки проверяют работу Docker командой запуска тестового контейнера:

```bash
sudo docker run --rm hello-world
```

Если контейнер успешно выполнился и вывел сообщение, Docker Engine настроен корректно. Для удобства работы можно добавить пользователя в группу docker, чтобы не использовать sudo (в учебных целях):

```bash
sudo usermod -aG docker $USER
newgrp docker
```

<a id="sec-2-2"></a>
### 2.2 Создание Dockerfile для веб‑приложения

Рассмотрим минимальный пример веб‑сервиса на Python (Flask), который возвращает строку «Hello, Docker!». Структура проекта может быть следующей:

```text
project/
  app.py
  requirements.txt
  Dockerfile
```

Содержимое файла app.py:

```python
from flask import Flask

app = Flask(__name__)

@app.get("/")
def index():
    return "Hello, Docker!"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
```

Файл requirements.txt:

```txt
flask==3.0.0
```

Dockerfile описывает сборку образа. В примере используется официальный базовый образ Python и установка зависимостей через pip <sup><a href="#ref-1">[1]</a></sup>:

```dockerfile
FROM python:3.12-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app.py .

EXPOSE 8000
CMD ["python", "app.py"]
```

Сборка и запуск выполняются командами:

```bash
docker build -t hello-docker:1.0 .
docker run --rm -p 8000:8000 hello-docker:1.0
```

После запуска сервис будет доступен по адресу http://localhost:8000/. При необходимости образ можно опубликовать в registry (например, Docker Hub или приватный репозиторий) и запускать на других машинах без повторной настройки окружения <sup><a href="#ref-1">[1]</a></sup>.

<a id="sec-2-3"></a>
### 2.3 Оркестрация нескольких сервисов с Docker Compose

Одиночный контейнер удобен для простых задач, но на практике приложения часто состоят из нескольких компонентов: веб‑приложение, база данных, кэш, обратный прокси. Docker Compose позволяет описать такую конфигурацию в файле docker-compose.yml и запускать её как единое целое <sup><a href="#ref-1">[1]</a></sup>.

Ниже приведен пример Compose‑файла для связки «приложение + PostgreSQL». Для упрощения предполагается, что приложение умеет читать параметры подключения из переменных окружения:

```yaml
version: "3.9"
services:
  db:
    image: postgres:16
    environment:
      POSTGRES_DB: appdb
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD: apppass
    volumes:
      - dbdata:/var/lib/postgresql/data

  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      DB_HOST: db
      DB_NAME: appdb
      DB_USER: appuser
      DB_PASSWORD: apppass
    depends_on:
      - db

volumes:
  dbdata:
```

Запуск выполняется командой:

```bash
docker compose up -d --build
```

Compose создаст отдельную сеть, поднимет контейнер базы данных и контейнер приложения, а также подключит том dbdata для сохранения данных PostgreSQL между перезапусками. Остановка и удаление окружения выполняются командой docker compose down (данные в томе при этом сохранятся, если не указать параметр -v) <sup><a href="#ref-1">[1]</a></sup>.

<a id="sec-2-4"></a>
### 2.4 Сравнение с развертыванием на виртуальной машине

Если аналогичное приложение разворачивать традиционно на виртуальной машине, администратору нужно выбрать ОС, установить интерпретатор Python, менеджер пакетов, зависимости, настроить службу (systemd) для автозапуска, организовать хранение конфигураций и учесть различия между окружениями. При переносе на другой сервер этот процесс придется повторять или автоматизировать отдельными инструментами.

Контейнеризация сводит развёртывание к запуску заранее собранного образа: зависимости фиксируются в Dockerfile, конфигурация задается переменными окружения, а окружение собирается и стартует одинаково на любых хостах с совместимым runtime. Это особенно полезно для тестовых стендов, учебных лабораторных работ и небольших продакшн‑развертываний, где требуется предсказуемость и быстрая доставка изменений.

При этом важно помнить, что контейнеризация не отменяет задач инфраструктуры: требуется мониторинг, управление секретами, резервное копирование данных, контроль доступа. В больших системах эти задачи обычно решаются средствами оркестрации и платформами уровня Kubernetes, которые работают поверх контейнеров и стандартизируют эксплуатацию на кластере узлов <sup><a href="#ref-9">[9]</a></sup>.

<a id="sec-conclusion"></a>
## Заключение

В ходе работы рассмотрены основы традиционной виртуализации и показано, что виртуальные машины обеспечивают сильную изоляцию за счет запуска отдельной гостевой операционной системы под управлением гипервизора. Такой подход остается актуальным там, где требуется запуск разнородных ОС и жесткое разделение сред выполнения <sup><a href="#ref-5">[5]</a></sup>, <sup><a href="#ref-6">[6]</a></sup>, <sup><a href="#ref-7">[7]</a></sup>.

Показано, что контейнеризация реализует изоляцию на уровне операционной системы (namespaces и cgroups) и позволяет запускать приложения значительно быстрее и экономичнее по ресурсам. Docker, опираясь на стандарты OCI, предоставляет удобные механизмы сборки, распространения и запуска контейнеров, что делает контейнеры практичным инструментом для разработки и эксплуатации сервисов <sup><a href="#ref-1">[1]</a></sup>, <sup><a href="#ref-2">[2]</a></sup>, <sup><a href="#ref-3">[3]</a></sup>, <sup><a href="#ref-4">[4]</a></sup>.

Практическая часть продемонстрировала базовый цикл работы с Docker: установка Docker Engine, сборка собственного образа через Dockerfile и запуск многокомпонентного окружения с помощью Docker Compose. Это иллюстрирует, почему контейнеризация часто рассматривается как современная альтернатива классической виртуализации в задачах, связанных с быстрым развертыванием и масштабированием приложений.

Таким образом, Docker и контейнеры не полностью вытесняют виртуальные машины, но существенно расширяют возможности администрирования: ускоряют поставку программных компонентов, повышают воспроизводимость окружений и позволяют эффективнее использовать вычислительные ресурсы. Оптимальный выбор между VM и контейнерами определяется требованиями к изоляции, совместимости ОС и особенностями конкретной инфраструктуры.

<a id="sec-references"></a>
## Список литературы

1. <a id="ref-1"></a> Docker Documentation (Docker Engine, images, networking, volumes, Compose). Доступ: <https://docs.docker.com/>

2. <a id="ref-2"></a> Open Container Initiative (OCI). Спецификации Image и Runtime (OCI). Доступ:
   - <https://opencontainers.org/>
   - <https://github.com/opencontainers/image-spec>
   - <https://github.com/opencontainers/runtime-spec>

3. <a id="ref-3"></a> Linux man-pages: namespaces(7) и связанные страницы руководства. Доступ: <https://man7.org/linux/man-pages/man7/namespaces.7.html>

4. <a id="ref-4"></a> Linux Kernel Documentation: Control Groups (cgroups) и cgroups v2. Доступ:
   - <https://docs.kernel.org/admin-guide/cgroup-v2.html>
   - <https://man7.org/linux/man-pages/man7/cgroups.7.html>

5. <a id="ref-5"></a> VMware. What is Virtualization? Доступ: <https://www.vmware.com/topics/glossary/content/virtualization.html>

6. <a id="ref-6"></a> Oracle VirtualBox. User Manual / Documentation. Доступ: <https://www.virtualbox.org/manual/>

7. <a id="ref-7"></a> Kernel-based Virtual Machine (KVM) Documentation. Доступ:
   - <https://www.linux-kvm.org/>
   - <https://docs.kernel.org/virt/kvm/index.html>

8. <a id="ref-8"></a> Red Hat. What is a container? / Containerization overview. Доступ: <https://www.redhat.com/en/topics/containers/what-is-a-container>

9. <a id="ref-9"></a> Kubernetes Documentation. Containers, Pods и container runtimes. Доступ:
   - <https://kubernetes.io/docs/>
   - <https://kubernetes.io/docs/concepts/workloads/pods/>
   - <https://kubernetes.io/docs/setup/production-environment/container-runtimes/>

10. <a id="ref-10"></a> NIST Special Publication 800-190. Application Container Security Guide (2017). Доступ: <https://csrc.nist.gov/publications/detail/sp/800-190/final>
